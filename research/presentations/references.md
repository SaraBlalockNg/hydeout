---
layout: default
title: References
sidebar_link: false
---
- Anderson, A. H., Bard,  e. G., Sotillo, C., Newlands, A., & Doherty-Sneddon, G. (1997). Limited visual control of the intelligibility of speech in face-to-face dialogue. Perception & Psychophysics, 39, 580–592.
- Aylett, M., & Turk, A. (2004). The smooth signal redundancy hypothesis: A functional explanation for relationships between redundancy, prosodic prominence, and duration in spontaneous speech. Language and Speech, 47(Pt 1), 31–56. https://doi.org/10.1177/00238309040470010201
- Baker, R., & Bradlow, A. (2009). Variability in word duration as a function of probability, speech style, and prosody. Language and Speech, 52(4), 391–413. https://doi.org/10.1177/0023830909336575
- Bögels, S., & Torreira, F. (2015). Listeners use intonational phrase boundaries to project turn ends in spoken interaction. Journal of Phonetics, 52, 46–57.
- Cassarly, C., Matthews, L. J., Simpson, A. N., & Dubno, J. R. (2020). The revised hearing handicap inventory and screening tool based on psychometric reevaluation of the hearing handicap inventories for the elderly and adults. Ear and Hearing, 41(1), 95.
- Cheang, H. S., & Pell, M. D. (2008). The sound of sarcasm. Speech Communication, 50(5), 366–381. doi: 10.1016/j.specom.2007.11.003
- Cieri, C., Miller, D., & Walker, K. (2004). Fisher English training speech parts 1 and 2. Linguistic Data Consortium.
- Cutler, A., & Ladd, D. R. (2013). Prosody: Models and measurements (Vol. 14). Springer Science & Business Media.
- De Ruiter, J.-P., Mitterer, H., & Enfield, N. J. (2006). Projecting the end of a speaker’s turn: A cognitive cornerstone of conversation. Language, 82(3), 515–535.
- Deshmukh, N., Ganapathiraju, A., Gleeson, A., Hamaker, J., & Picone, J. (1998). Resegmentation of SWITCHBOARD. ICSLP. Syndey.
- Ekberg, K., Hickson, L., & Grenness, C. (2017). Conversation breakdowns in the audiology clinic: The importance of mutual gaze. International Journal of Language & Communication Disorders, 52(3), 346–355. https://doi.org/10.1111/1460-6984.12277
- Fernandez, R., Rendel, A., Ramabhadran, B., & Hoory, R. (2014). Prosody Contour Prediction with Long Short-Term Memory, Bi-Directional, Deep Recurrent Neural Networks. Proc. INTERSPEECH 2014.
- Freeman, V. (2014). Acoustic indicators of stance in the ATAROS corpus. Purdue Linguistics Association Meeting, West Lafayette, Indiana. Retrieved from https://www.academia.edu/download/39475313/Freeman_2014_Purdue-slides.pdf
- Freeman, V. (2015). The phonetics of stance-taking (Ph.D. dissertation, University of Washington). University of Washington, United States -- Washington. Retrieved from https://depts.washington.edu/phonlab/pubs/Freeman_2015_dissertation.pdf
- Freeman, V., Chan, J., Levow, G.-A., Wright, R., Ostendorf, M., & Zayats, V. (2014). Manipulating stance and involvement using collaborative tasks: An exploratory comparison. Proc. INTERSPEECH 2014, 303–307. doi: 10.21437/Interspeech.2014-73
- Godfrey, J. J., Holliman, E. C., & McDaniel, J. (1992). SWITCHBOARD: Telephone speech corpus for research and development. Proc. ICASSP 1992, 1, 517–520. IEEE Computer Society. Retrieved from https://www.computer.org/csdl/proceedings-article/icassp/1992/00225858/12OmNxGSmbC
- Goman, A. M., & Lin, F. R. (2016). Prevalence of Hearing Loss by Severity in the United States. American Journal of Public Health, 106(10), 1820. https://doi.org/10.2105/AJPH.2016.303299
- Hard, A., Partridge, K., Chen, N., Augenstein, S., Shah, A., Park, H. J., … Moreno, I. L. (2022). Production federated keyword spotting via distillation, filtering, and joint federated-centralized training. Proc. INTERSPEECH 2022. Presented at the INTERSPEECH. doi: 10.48550/arXiv.2204.06322 Focus to learn more
- Hodari, Z., Moinet, A., Karlapati, S., Lorenzo-Trueba, J., Merritt, T., Joly, A., … Drugman, T. (2021). Camp: A Two-Stage Approach to Modelling Prosody in Context. Proc. ICASSP 2021, 6578–6582. doi: 10.1109/ICASSP39728.2021.9414413
- Hymes, D. (1972). On communicative competence. Sociolinguistics, 269293, 269–293.
- Jokinen, K. (2010). Non-verbal signals for turn-taking and feedback. Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10). Presented at the LREC 2010, Valletta, Malta. Valletta, Malta: European Language Resources Association (ELRA). Retrieved from http://www.lrec-conf.org/proceedings/lrec2010/pdf/173_Paper.pdf
- Jurafsky, D., & Martin, J. H. (2024). Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition (3rd ed.).
- Jurafsky, D., Shriberg, E., & Biasca, D. (1997). Switchboard SWBD-DAMSL shallow-discourse-function annotation coders manual, draft 13 (No. 97–02). Boulder, CO: University of Colorado, Boulder Institute of Cognitive Science.
- Katz, J., & Selkirk, E. (2011). Contrastive focus vs. discourse-new: Evidence from phonetic prominence in English. Language, 771–816. https://doi.org/10.1353/lan.2011.0076
- Levow, G.-A., Freeman, V., Hrynkevich, A., Ostendorf, M., Wright, R., Chan, J., … Tran, T. (2014). Recognition of stance strength and polarity in spontaneous speech. 2014 IEEE Spoken Language Technology Workshop (SLT), 236–241. IEEE. Retrieved from https://ieeexplore.ieee.org/abstract/document/7078580/
- Levow, G.-A., & Wright, R. A. (2017). Exploring dynamic measures of stance in spoken interaction. Proc. INTERSPEECH 2017, 1452–1456. doi: 10.21437/Interspeech.2017-1706
- Levow, G.-A., Freeman, V., Hrynkevich, A., Ostendorf, M., Wright, R., Chan, J., Luan, Y., & Tran, T. (2014). Recognition of stance strength and polarity in spontaneous speech. 2014 IEEE Spoken Language Technology Workshop (SLT), 236–241. https://ieeexplore.ieee.org/abstract/document/7078580/
- Liljencrants, J., Lindblom, B., & Lindblom, B. (1972). Numerical simulation of vowel quality systems: The role of perceptual contrast. Language, 48(4), 839. https://doi.org/10.2307/411991
- Lind, C., Hickson, L., & Erber, N. (2010). Who Said What? Sampling Conversation Repair Behavior Involving Adults with Acquired Hearing Impairment. Seminars in Hearing, 31(02), 104–115. https://doi.org/10.1055/s-0030-1252104
- Mannel, R., Cox, F., & Harrington, J. (2014). Introduction to prosody theories and models [Web_content]. Retrieved February 13, 2024, from Macquarie University website: https://www.mq.edu.au/about/about-the-university/our-faculties/medicine-and-health-sciences/departments-and-centres/department-of-linguistics/our-research/phonetics-and-phonology/speech/phonetics-and-phonology/intonation-prosody
- McCloy, D. (2013). Prosody, intelligibility and familiarity in speech perception [Doctoral Dissertation, University of Washington]. https://www.proquest.com/docview/1428432833/abstract/6DC403BCC4A64D16PQ/1
- Ng, S., Ellis, G. M., Souza, P. E., Gallun, F. J., Wright, R. A., & Ostendorf, M. (2021). Assessing the stability of the spectro-temporal cue weighting angle for listener categorization. Proceedings of Meetings on Acoustics 181ASA, 45, 050009. Acoustical Society of America.
- Nygaard, L. C., Patel, N., & Queen, J. S. (2002). The link between prosody and meaning in the production of emotional homophones. The Journal of the Acoustical Society of America, 112(5_Supplement), 2444–2444.
- Pichora‐Fuller, M. K., Johnson, C. E., & Roodenburg, K. E. J. (1998). The discrepancy between hearing impairment and handicap in the elderly: Balancing transaction and interaction in conversation. Journal of Applied Communication Research, 26(1), 99–119. https://doi.org/10.1080/00909889809365494
- Reece, A., Cooney, G., Bull, P., Chung, C., Dawson, B., Fitzpatrick, C., … Marin, S. (2023). The CANDOR corpus: Insights from a large multimodal dataset of naturalistic conversation. Science Advances, 9(13), eadf3197. doi: 10.1126/sciadv.adf3197
- Qian, Y., Wu, Z., Ma, X., & Soong, F. (2010). Automatic prosody prediction and detection with Conditional Random Field (CRF) models. 2010 7th International Symposium on Chinese Spoken Language Processing, 135–138. Tainan, Taiwan: IEEE. doi: 10.1109/ISCSLP.2010.5684835
- Sacks, H., Schegloff, E. A., & Jefferson, G. (1978). A simplest systematics for the organization of turn taking for conversation. In Studies in the organization of conversational interaction (pp. 7–55). Elsevier.
- Shannon, C. E. (1948). A mathematical theory of communication. The Bell System Technical Journal, 27(3), 379–423.
- Stephens, S. D., Jaworski, A., Lewis, P., & Aslan, S. (1999). An analysis of the communication tactics used by hearing-impaired adults. British Journal of Audiology, 33(1), 17–27. https://doi.org/10.3109/03005364000000097
- Syrdal, A. K., Hirschberg, J., McGory, J., & Beckman, M. (2001). Automatic ToBI prediction and alignment to speed manual labeling of prosody. Speech Communication.
- Tomita, K. (2008). Effects of word familiarity in contexts on speaker’s vowel articulation. Bulletin of Yamagata University: Humanities, 16(3), 55–64.
- Tran, T. (2020). Neural Models for Integrating Prosody in Spoken Language Understanding (PhD Thesis). University of Washington.
- Tran, T., Toshniwal, S., Bansal, M., Gimpel, K., Livescu, K., & Ostendorf, M. (2018). Parsing speech: A neural approach to integrating lexical and acoustic-prosodic information. In M. Walker, H. Ji, & A. Stent (Eds.), Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Vol. 1 (Long Papers) (pp. 69–81). New Orleans, Louisiana: Association for Computational Linguistics. doi: 10.18653/v1/N18-1007
- Tran, T., Yuan, J., Liu, Y., & Ostendorf, M. (2019). On the Role of Style in Parsing Speech with Neural Models. 4190–4194. doi: 10.21437/Interspeech.2019-3122
- Wright, R. (2004). Factors of lexical competition in vowel articulation. In Phonetic Interpretation (pp. 75–87). Cambridge University Press.
- Xu, Y., Chen, S., & Wang, B. (2012). Prosodic focus with and without post-focus compression: A typological divide within the same language family? The Linguistic Review, 29(1), 131–147. doi: 10.1515/tlr-2012-0006
- Yin, Y., Ananthabhotla, I., Ithapu, V. K., Petridis, S., Wu, Y.-H., & Miller, C. (2024, January 16). Hearing loss detection from facial expressions in one-on-one conversations. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). https://doi.org/10.1109/ICASSP48485.2024.10446324
- Yuan, J., & Liberman, M. (2008). Speaker identification on the SCOTUS corpus. Acoustical Society of America Journal, 123(5), 3878.
- Zayats, V., & Ostendorf, M. (2019). Giving Attention to the Unexpected: Using Prosody Innovations in Disfluency Detection. In J. Burstein, C. Doran, & T. Solorio (Eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 86–95). Minneapolis, Minnesota: Association for Computational Linguistics. doi: 10.18653/v1/N19-1008
- Zazove, P., Plegue, M. A., McKee, M. M., DeJonckheere, M., Kileny, P. R., Schleicher, L. S., Green, L. A., Sen, A., Rapai, M. E., & Mulhem, E. (2020). Effective Hearing Loss Screening in Primary Care: The Early Auditory Referral-Primary Care Study. The Annals of Family Medicine, 18(6), 520–527. https://doi.org/10.1370/afm.2590
